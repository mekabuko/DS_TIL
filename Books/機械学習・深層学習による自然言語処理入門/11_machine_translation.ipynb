{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11_machine_translation.ipynb","provenance":[{"file_id":"1J5VEOARdZjeJkRGA0a5zgrrCU_7zy2bY","timestamp":1627915265052},{"file_id":"1QtAK-nUbYxpLpX1O7nuuYEv8gq_YWnkf","timestamp":1579656948385}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w3hrr_5ID8UR"},"source":["# Machine Translation using Sequence to Sequence Model"]},{"cell_type":"markdown","metadata":{"id":"K10r2gMqy3fs"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"6mig8tzFyqqZ"},"source":["%tensorflow_version 2.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UxjEYBTpyuu-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605531030902,"user_tz":-540,"elapsed":2626,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"e28c5877-fa78-4b2e-9fc9-69ad5d38c256"},"source":["!pip install janome nltk"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: janome in /usr/local/lib/python3.6/dist-packages (0.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GGzMX97ey2Hy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605531056086,"user_tz":-540,"elapsed":13791,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"f35446ce-3f07-4033-b70f-db8edc251e62"},"source":["!mkdir data\n","!mkdir models\n","!wget http://www.manythings.org/anki/jpn-eng.zip -P data/\n","!unzip data/jpn-eng.zip -d data/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘data’: File exists\n","mkdir: cannot create directory ‘models’: File exists\n","--2020-11-16 12:50:42--  http://www.manythings.org/anki/jpn-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 172.67.173.198, ...\n","Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2387505 (2.3M) [application/zip]\n","Saving to: ‘data/jpn-eng.zip.3’\n","\n","jpn-eng.zip.3       100%[===================>]   2.28M  8.76MB/s    in 0.3s    \n","\n","2020-11-16 12:50:43 (8.76 MB/s) - ‘data/jpn-eng.zip.3’ saved [2387505/2387505]\n","\n","Archive:  data/jpn-eng.zip\n","replace data/jpn.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace data/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JrgeUVRVEMxw"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"Xgn6UKiZEOjU"},"source":["from collections import defaultdict\n","\n","import numpy as np\n","import tensorflow as tf\n","from janome.tokenizer import Tokenizer\n","from nltk.translate.bleu_score import corpus_bleu\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.layers import Dense, Input, Embedding, GRU, Dot, Activation, Concatenate\n","from tensorflow.keras.models import Model, model_from_json\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aMyR2WdSFZXD"},"source":["### Hyper-parameters"]},{"cell_type":"code","metadata":{"id":"P9n0yH5PFb9H"},"source":["batch_size = 32\n","epochs = 100\n","model_path = 'models/mode.h5'\n","enc_arch = 'models/encoder.json'\n","dec_arch = 'models/decoder.json'\n","data_path = 'data/jpn.txt'\n","num_words = 10000\n","num_data = 20000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywMXtZJ4zHCv"},"source":["## The dataset"]},{"cell_type":"markdown","metadata":{"id":"i2pZcwgqF12t"},"source":["### Load the Bilingual Sentence Pairs"]},{"cell_type":"code","metadata":{"id":"XYcG4pBazEVB"},"source":["def load_dataset(filename):\n","    # wget http://www.manythings.org/anki/jpn-eng.zip\n","    en_texts = []\n","    ja_texts = []\n","    with open(filename) as f:\n","        for line in f:\n","            en_text, ja_text = line.strip().split('\\t')[:2]\n","            en_texts.append(en_text)\n","            ja_texts.append(ja_text)\n","    return en_texts, ja_texts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nI1nczVF-g5"},"source":["en_texts, ja_texts = load_dataset(data_path)\n","en_texts, ja_texts = en_texts[:num_data], ja_texts[:num_data]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B0-kKt_dzMWw"},"source":["### Preprocess the dataset"]},{"cell_type":"code","metadata":{"id":"Lkx3CQTbzLbc"},"source":["t = Tokenizer(wakati=True)\n","\n","\n","def tokenize(text):\n","    return t.tokenize(text)\n","\n","\n","def build_vocabulary(texts, num_words=None):\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        num_words=num_words, oov_token='<UNK>', filters=''\n","    )\n","    tokenizer.fit_on_texts(texts)\n","    return tokenizer\n","\n","\n","def preprocess_dataset(texts):\n","    return ['<start> {} <end>'.format(text) for text in texts]\n","\n","\n","def preprocess_ja(texts):\n","    return [' '.join(tokenize(text)) for text in texts]\n","\n","\n","def create_dataset(en_texts, ja_texts, en_vocab, ja_vocab):\n","    en_seqs = en_vocab.texts_to_sequences(en_texts)\n","    ja_seqs = ja_vocab.texts_to_sequences(ja_texts)\n","    en_seqs = pad_sequences(en_seqs, padding='post')\n","    ja_seqs = pad_sequences(ja_seqs, padding='post')\n","    return [en_seqs, ja_seqs[:, :-1]], ja_seqs[:, 1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vyOnVjSkGV3-"},"source":["ja_texts = preprocess_ja(ja_texts)\n","ja_texts = preprocess_dataset(ja_texts)\n","en_texts = preprocess_dataset(en_texts)\n","x_train, x_test, y_train, y_test = train_test_split(en_texts, ja_texts, test_size=0.2, random_state=42)\n","en_vocab = build_vocabulary(x_train, num_words)\n","ja_vocab = build_vocabulary(y_train, num_words)\n","x_train, y_train = create_dataset(x_train, y_train, en_vocab, ja_vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9XGJluw5zQ7e"},"source":["## The models"]},{"cell_type":"markdown","metadata":{"id":"Devy77-sGndg"},"source":["### Build a simple model"]},{"cell_type":"code","metadata":{"id":"OLxqrW_0zQGB"},"source":["class BaseModel:\n","\n","    def build(self):\n","        raise NotImplementedError()\n","\n","    def save_as_json(self, filepath):\n","        model = self.build()\n","        with open(filepath, 'w') as f:\n","            f.write(model.to_json())\n","\n","    @classmethod\n","    def load(cls, architecture_file, weight_file, by_name=True):\n","        with open(architecture_file) as f:\n","            model = model_from_json(f.read())\n","            model.load_weights(weight_file, by_name=by_name)\n","            return model\n","\n","\n","class Encoder(BaseModel):\n","\n","    def __init__(self, input_dim, emb_dim=300, hid_dim=256, return_sequences=False):\n","        self.input = Input(shape=(None,), name='encoder_input')\n","        self.embedding = Embedding(input_dim=input_dim,\n","                                   output_dim=emb_dim,\n","                                   mask_zero=True,\n","                                   name='encoder_embedding')\n","        self.gru = GRU(hid_dim,\n","                       return_sequences=return_sequences,\n","                       return_state=True,\n","                       name='encoder_gru')\n","\n","    def __call__(self):\n","        x = self.input\n","        embedding = self.embedding(x)\n","        output, state = self.gru(embedding)\n","        return output, state\n","\n","    def build(self):\n","        output, state = self()\n","        return Model(inputs=self.input, outputs=[output, state])\n","\n","\n","class Decoder(BaseModel):\n","\n","    def __init__(self, output_dim, emb_dim=300, hid_dim=256):\n","        self.input = Input(shape=(None,), name='decoder_input')\n","        self.embedding = Embedding(input_dim=output_dim,\n","                                   output_dim=emb_dim,\n","                                   mask_zero=True,\n","                                   name='decoder_embedding')\n","        self.gru = GRU(hid_dim,\n","                       return_sequences=True,\n","                       return_state=True,\n","                       name='decoder_gru')\n","        self.dense = Dense(output_dim, activation='softmax', name='decoder_output')\n","\n","        # for inference.\n","        self.state_input = Input(shape=(hid_dim,), name='decoder_state_in')\n","\n","    def __call__(self, states, enc_output=None):\n","        x = self.input\n","        embedding = self.embedding(x)\n","        outputs, state = self.gru(embedding, initial_state=states)\n","        outputs = self.dense(outputs)\n","        return outputs, state\n","\n","    def build(self):\n","        decoder_output, decoder_state = self(states=self.state_input)\n","        return Model(\n","            inputs=[self.input, self.state_input],\n","            outputs=[decoder_output, decoder_state])\n","\n","\n","class LuongAttention:\n","\n","    def __init__(self, units=300):\n","        self.dot = Dot(axes=[2, 2], name='dot')\n","        self.attention = Activation(activation='softmax', name='attention')\n","        self.context = Dot(axes=[2, 1], name='context')\n","        self.concat = Concatenate(name='concat')\n","        self.fc = Dense(units, activation='tanh', name='attn_out')\n","\n","    def __call__(self, enc_output, dec_output):\n","        attention = self.dot([dec_output, enc_output])\n","        attention_weight = self.attention(attention)\n","        context_vector = self.context([attention_weight, enc_output])\n","        concat_vector = self.concat([context_vector, dec_output])\n","        output = self.fc(concat_vector)\n","        return output\n","\n","\n","class AttentionDecoder(Decoder):\n","\n","    def __init__(self, output_dim, emb_dim=300, hid_dim=256):\n","        super().__init__(output_dim, emb_dim, hid_dim)\n","        self.attention = LuongAttention()\n","        self.enc_output = Input(shape=(None, hid_dim), name='encoder_output')\n","\n","    def __call__(self, states, enc_output=None):\n","        x = self.input\n","        embedding = self.embedding(x)\n","        outputs, state = self.gru(embedding, initial_state=states)\n","        outputs = self.attention(enc_output, outputs)\n","        outputs = self.dense(outputs)\n","        return outputs, state\n","\n","    def build(self):\n","        decoder_output, decoder_state = self(states=self.state_input,\n","                                             enc_output=self.enc_output)\n","        return Model(\n","            inputs=[self.input, self.enc_output, self.state_input],\n","            outputs=[decoder_output, decoder_state])\n","\n","\n","class Seq2seq(BaseModel):\n","\n","    def __init__(self, encoder, decoder):\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def build(self):\n","        encoder_output, state = self.encoder()\n","        decoder_output, _ = self.decoder(states=state, enc_output=encoder_output)\n","        return Model([self.encoder.input, self.decoder.input], decoder_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ze_OYeyEGyHB"},"source":["encoder = Encoder(num_words)\n","decoder = Decoder(num_words)\n","seq2seq = Seq2seq(encoder, decoder)\n","model = seq2seq.build()\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W120s1MZG3m-"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"b6IxGcCJG5Uf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605531464887,"user_tz":-540,"elapsed":399471,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"7570f8bd-7950-4fda-9512-6c97832bf063"},"source":["callbacks = [\n","    EarlyStopping(patience=3),\n","    ModelCheckpoint(model_path, save_best_only=True, save_weights_only=True)\n","]\n","model.fit(x=x_train,\n","          y=y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          callbacks=callbacks,\n","          validation_split=0.1)\n","\n","encoder.save_as_json(enc_arch)\n","decoder.save_as_json(dec_arch)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","450/450 [==============================] - 34s 75ms/step - loss: 1.6873 - val_loss: 1.3110\n","Epoch 2/100\n","450/450 [==============================] - 32s 72ms/step - loss: 1.1368 - val_loss: 1.1096\n","Epoch 3/100\n","450/450 [==============================] - 32s 71ms/step - loss: 0.9365 - val_loss: 1.0150\n","Epoch 4/100\n","450/450 [==============================] - 31s 70ms/step - loss: 0.7901 - val_loss: 0.9581\n","Epoch 5/100\n","450/450 [==============================] - 31s 70ms/step - loss: 0.6679 - val_loss: 0.9225\n","Epoch 6/100\n","450/450 [==============================] - 31s 69ms/step - loss: 0.5605 - val_loss: 0.8894\n","Epoch 7/100\n","450/450 [==============================] - 31s 70ms/step - loss: 0.4666 - val_loss: 0.8723\n","Epoch 8/100\n","450/450 [==============================] - 31s 69ms/step - loss: 0.3854 - val_loss: 0.8604\n","Epoch 9/100\n","450/450 [==============================] - 31s 70ms/step - loss: 0.3180 - val_loss: 0.8602\n","Epoch 10/100\n","450/450 [==============================] - 32s 70ms/step - loss: 0.2609 - val_loss: 0.8628\n","Epoch 11/100\n","450/450 [==============================] - 31s 69ms/step - loss: 0.2149 - val_loss: 0.8668\n","Epoch 12/100\n","450/450 [==============================] - 31s 69ms/step - loss: 0.1769 - val_loss: 0.8805\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o6E9-XVtHG2U"},"source":["### Evaluate the model"]},{"cell_type":"markdown","metadata":{"id":"JPmSUZ89zZl7"},"source":["#### Define Inference classes"]},{"cell_type":"code","metadata":{"id":"C5PI1hJzzVyu"},"source":["class InferenceAPI:\n","    \"\"\"A model API that generates output sequence.\n","\n","    Attributes:\n","        encoder_model: Model.\n","        decoder_model: Model.\n","        en_vocab: source language's vocabulary.\n","        ja_vocab: target language's vocabulary.\n","    \"\"\"\n","\n","    def __init__(self, encoder_model, decoder_model, en_vocab, ja_vocab):\n","        self.encoder_model = encoder_model\n","        self.decoder_model = decoder_model\n","        self.en_vocab = en_vocab\n","        self.ja_vocab = ja_vocab\n","\n","    def predict(self, text):\n","        output, state = self._compute_encoder_output(text)\n","        sequence = self._generate_sequence(output, state)\n","        decoded = self._decode(sequence)\n","        return decoded\n","\n","    def _compute_encoder_output(self, text):\n","        \"\"\"Compute encoder output.\n","\n","        Args:\n","            text : string, the input text.\n","\n","        Returns:\n","            output: encoder's output.\n","            state : encoder's final state.\n","        \"\"\"\n","        assert isinstance(text, str)\n","        x = self.en_vocab.texts_to_sequences([text])\n","        output, state = self.encoder_model.predict(x)\n","        return output, state\n","\n","    def _compute_decoder_output(self, target_seq, state, enc_output=None):\n","        \"\"\"Compute decoder output.\n","\n","        Args:\n","            target_seq: target sequence.\n","            state: hidden state.\n","            output: encoder's output.\n","\n","        Returns:\n","            output: decoder's output.\n","            state: decoder's state.\n","        \"\"\"\n","        output, state = self.decoder_model.predict([target_seq, state])\n","        return output, state\n","\n","    def _generate_sequence(self, enc_output, state, max_seq_len=50):\n","        \"\"\"Generate a sequence.\n","\n","        Args:\n","            states: initial states of the decoder.\n","\n","        Returns:\n","            sampled: a generated sequence.\n","        \"\"\"\n","        target_seq = np.array([self.ja_vocab.word_index['<start>']])\n","        sequence = []\n","        for i in range(max_seq_len):\n","            output, state = self._compute_decoder_output(target_seq, state, enc_output)\n","            sampled_token_index = np.argmax(output[0, 0])\n","            if sampled_token_index == self.ja_vocab.word_index['<end>']:\n","                break\n","            sequence.append(sampled_token_index)\n","            target_seq = np.array([sampled_token_index])\n","        return sequence\n","\n","    def _decode(self, sequence):\n","        \"\"\"Decode a sequence.\n","\n","        Args:\n","            sequence: a generated sequence.\n","\n","        Returns:\n","            decoded: a decoded sequence.\n","        \"\"\"\n","        decoded = self.ja_vocab.sequences_to_texts([sequence])\n","        decoded = decoded[0].split(' ')\n","        return decoded\n","\n","\n","class InferenceAPIforAttention(InferenceAPI):\n","\n","    def _compute_decoder_output(self, target_seq, state, enc_output=None):\n","        output, state = self.decoder_model.predict([target_seq, enc_output, state])\n","        return output, state"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u619OblqHQ_l"},"source":["#### Define evaluation function"]},{"cell_type":"code","metadata":{"id":"s3CL21CgHTp1"},"source":["def evaluate_bleu(X, y, api):\n","    d = defaultdict(list)\n","    for source, target in zip(X, y):\n","        d[source].append(target)\n","    hypothesis = []\n","    references = []\n","    for source, targets in d.items():\n","        pred = api.predict(source)\n","        hypothesis.append(pred)\n","        references.append(targets)\n","    bleu_score = corpus_bleu(references, hypothesis)\n","    return bleu_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9hP0J3THZxE"},"source":["#### Perform evaluation"]},{"cell_type":"code","metadata":{"id":"zkBTngl6HdxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605532579485,"user_tz":-540,"elapsed":1509327,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"8b13806a-5385-4bd1-eed6-4ffb673cee4d"},"source":["encoder = Encoder.load(enc_arch, model_path)\n","decoder = Decoder.load(dec_arch, model_path)\n","api = InferenceAPI(encoder, decoder, en_vocab, ja_vocab)\n","texts = sorted(set(en_texts[:50]), key=len)\n","for text in texts:\n","    decoded = api.predict(text=text)\n","    print('English : {}'.format(text))\n","    print('Japanese: {}'.format(decoded))\n","\n","y_test = [y.split(' ')[1:-1] for y in y_test]\n","bleu_score = evaluate_bleu(x_test, y_test, api)\n","print('BLEU: {}'.format(bleu_score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["English : <start> Go. <end>\n","Japanese: ['何', 'か', '。']\n","English : <start> Hi. <end>\n","Japanese: ['おめでとう', '。']\n","English : <start> Who? <end>\n","Japanese: ['誰', '？']\n","English : <start> Wow! <end>\n","Japanese: ['ワォ', '！']\n","English : <start> Run. <end>\n","Japanese: ['くつろい', 'だ', '。']\n","English : <start> Wait! <end>\n","Japanese: ['待っ', 'て', '！']\n","English : <start> Fire! <end>\n","Japanese: ['撃て', '！']\n","English : <start> Jump. <end>\n","Japanese: ['飛び降りろ', '！']\n","English : <start> Help! <end>\n","Japanese: ['お', '入り', 'ください', '。']\n","English : <start> Jump! <end>\n","Japanese: ['飛び降りろ', '！']\n","English : <start> Stop! <end>\n","Japanese: ['おめでとう', '！']\n","English : <start> Hello! <end>\n","Japanese: ['こんにちは', '。']\n","English : <start> Go on. <end>\n","Japanese: ['出', 'て', 'いけ', '。']\n","English : <start> I try. <end>\n","Japanese: ['やっ', 'て', 'みる', '。']\n","English : <start> Hurry! <end>\n","Japanese: ['急げ', '！']\n","English : <start> I won! <end>\n","Japanese: ['私', 'は', '勝ち', '！']\n","English : <start> I see. <end>\n","Japanese: ['わかり', 'まし', 'た', '。']\n","BLEU: 0.19890089691474233\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"urEKbwMoH_MV"},"source":["### Build an attention model"]},{"cell_type":"code","metadata":{"id":"TP9-Ye87ICY9"},"source":["encoder = Encoder(num_words, return_sequences=True)\n","decoder = AttentionDecoder(num_words)\n","seq2seq = Seq2seq(encoder, decoder)\n","model = seq2seq.build()\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0nGarGNLIIpZ"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"SUDtHeuaIN7T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605533054194,"user_tz":-540,"elapsed":1980416,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"13214939-ddc7-4634-d2fb-c34f8134e935"},"source":["callbacks = [\n","    EarlyStopping(patience=3),\n","    ModelCheckpoint(model_path, save_best_only=True, save_weights_only=True)\n","]\n","model.fit(x=x_train,\n","          y=y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          callbacks=callbacks,\n","          validation_split=0.1)\n","\n","encoder.save_as_json(enc_arch)\n","decoder.save_as_json(dec_arch)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","450/450 [==============================] - 35s 78ms/step - loss: 1.7598 - val_loss: 1.4590\n","Epoch 2/100\n","450/450 [==============================] - 34s 74ms/step - loss: 1.3043 - val_loss: 1.2602\n","Epoch 3/100\n","450/450 [==============================] - 34s 75ms/step - loss: 1.1069 - val_loss: 1.1399\n","Epoch 4/100\n","450/450 [==============================] - 33s 74ms/step - loss: 0.9636 - val_loss: 1.0698\n","Epoch 5/100\n","450/450 [==============================] - 33s 74ms/step - loss: 0.8357 - val_loss: 1.0103\n","Epoch 6/100\n","450/450 [==============================] - 33s 73ms/step - loss: 0.7197 - val_loss: 0.9639\n","Epoch 7/100\n","450/450 [==============================] - 33s 73ms/step - loss: 0.6144 - val_loss: 0.9251\n","Epoch 8/100\n","450/450 [==============================] - 33s 73ms/step - loss: 0.5192 - val_loss: 0.9055\n","Epoch 9/100\n","450/450 [==============================] - 33s 73ms/step - loss: 0.4358 - val_loss: 0.8919\n","Epoch 10/100\n","450/450 [==============================] - 33s 74ms/step - loss: 0.3618 - val_loss: 0.8853\n","Epoch 11/100\n","450/450 [==============================] - 33s 73ms/step - loss: 0.2993 - val_loss: 0.8833\n","Epoch 12/100\n","450/450 [==============================] - 33s 73ms/step - loss: 0.2466 - val_loss: 0.8935\n","Epoch 13/100\n","450/450 [==============================] - 33s 74ms/step - loss: 0.2046 - val_loss: 0.8970\n","Epoch 14/100\n","450/450 [==============================] - 33s 74ms/step - loss: 0.1700 - val_loss: 0.9091\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ODIE-R9RIWVQ"},"source":["### Evaluate the model"]},{"cell_type":"code","metadata":{"id":"0NfxwW6dIYLu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605534297493,"user_tz":-540,"elapsed":3221895,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"a3dc63e7-fe69-4757-aee5-e3ab652d8c7f"},"source":["encoder = Encoder.load(enc_arch, model_path)\n","decoder = Decoder.load(dec_arch, model_path)\n","api = InferenceAPIforAttention(encoder, decoder, en_vocab, ja_vocab)\n","bleu_score = evaluate_bleu(x_test, y_test, api)\n","print('BLEU: {}'.format(bleu_score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BLEU: 0.21558149696078754\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mGJzIGXkbRav"},"source":[""],"execution_count":null,"outputs":[]}]}