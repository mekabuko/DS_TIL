{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Chapter09.ipynb","provenance":[{"file_id":"https://github.com/stockmarkteam/bert-book/blob/master/Chapter9.ipynb","timestamp":1630964959899},{"file_id":"https://github.com/stockmarkteam/bert-book/blob/master/Chapter9.ipynb","timestamp":1630577154754}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3716ce24971b46888a8e5c8a4039f569":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e243c05139fa4d40b5686e2d44e94710","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9779f522a866455d8752d682ad547fce","IPY_MODEL_558085a6721c4307ba47d199bae5dcb1","IPY_MODEL_12c701e661004815968c266a6d4c3f39"]}},"e243c05139fa4d40b5686e2d44e94710":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9779f522a866455d8752d682ad547fce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7d3953c604074d5c9d13c7e0e9305a1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b21db5a1f334860b2cf9cf15dfb6614"}},"558085a6721c4307ba47d199bae5dcb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_042072428cd3420392a0e3ce6ed48e63","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":257706,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":257706,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_233672f056824eb6a64dc733ba9264c3"}},"12c701e661004815968c266a6d4c3f39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a50203ed76e4123beb66fc6ad728e1b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 258k/258k [00:00&lt;00:00, 314kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a310795d4e784b54b0721e85cc7146a7"}},"7d3953c604074d5c9d13c7e0e9305a1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b21db5a1f334860b2cf9cf15dfb6614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"042072428cd3420392a0e3ce6ed48e63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"233672f056824eb6a64dc733ba9264c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a50203ed76e4123beb66fc6ad728e1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a310795d4e784b54b0721e85cc7146a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08f894b1a91244808fb69ec50f7e2de1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cefb21e32dab42a1b75939a81eef323e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_23d5d09797314b25a2fd78661e145897","IPY_MODEL_a6f87ac9d26b4d4680f4c9fa305c9e9e","IPY_MODEL_c934043aac174925b98c0ed88540e98a"]}},"cefb21e32dab42a1b75939a81eef323e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23d5d09797314b25a2fd78661e145897":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a7bdf955d7d043f7be9434d6840bdde8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f08ef83a0884ca3a2abb0fd3c0bbc29"}},"a6f87ac9d26b4d4680f4c9fa305c9e9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1cd433d83c5942219f0659fbb05f44d9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":110,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":110,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7b0b4f55ba54d1db73ae46f29ded42b"}},"c934043aac174925b98c0ed88540e98a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_458c8ab270944cb8adee9ca249888981","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 110/110 [00:00&lt;00:00, 2.50kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f5b39d1c75f472892fa33a9cb8b75d8"}},"a7bdf955d7d043f7be9434d6840bdde8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f08ef83a0884ca3a2abb0fd3c0bbc29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cd433d83c5942219f0659fbb05f44d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c7b0b4f55ba54d1db73ae46f29ded42b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"458c8ab270944cb8adee9ca249888981":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f5b39d1c75f472892fa33a9cb8b75d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9992f74f0c2740748daf57db10e21b06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1419bc5ace0941e89dd5ccc46e3f6c7b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ada96e2d437c483a93a5564f3d14312b","IPY_MODEL_6f994482f0ae47b98c82f88611232650","IPY_MODEL_dc67e59186c44521b9710f2ac420693e"]}},"1419bc5ace0941e89dd5ccc46e3f6c7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ada96e2d437c483a93a5564f3d14312b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dcd2cc76094443a7933564f2e7945ec6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_391cd293e8ef4bff91133e020e47e254"}},"6f994482f0ae47b98c82f88611232650":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_096f486c426f4f4bbadbc684742bafef","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":479,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":479,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0b0086061d44ce2a60f24fdf5306531"}},"dc67e59186c44521b9710f2ac420693e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d18306992b74f688c0eda66c78c287f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 479/479 [00:00&lt;00:00, 12.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2301e04a5a640289179a2cc90017a17"}},"dcd2cc76094443a7933564f2e7945ec6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"391cd293e8ef4bff91133e020e47e254":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"096f486c426f4f4bbadbc684742bafef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a0b0086061d44ce2a60f24fdf5306531":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d18306992b74f688c0eda66c78c287f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a2301e04a5a640289179a2cc90017a17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1fb19a3e278e4f6199dd2ac49cdd0cc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_565ae0aa43994a10a91deb516daa2602","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_73bd4e52f4d24a0c91e2bc097a0e1c89","IPY_MODEL_03a296822f654bed96fbcc76fde7c7d3","IPY_MODEL_cdd88c2ff77041bcaf4c6eb0b40a5514"]}},"565ae0aa43994a10a91deb516daa2602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73bd4e52f4d24a0c91e2bc097a0e1c89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_27d36944757d4939ad4a03b45282cad2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41c6cc03d1fc4c35be4733db3749d465"}},"03a296822f654bed96fbcc76fde7c7d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a3bba3b7eaf24996a82de677cdc8b351","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":445021143,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":445021143,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3e7745228e64f5894fb948559c29360"}},"cdd88c2ff77041bcaf4c6eb0b40a5514":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_da84abcf648e411480168c3b87ffb4ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 445M/445M [00:12&lt;00:00, 37.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35dcbc99749b4c8ca85da311464a1f1e"}},"27d36944757d4939ad4a03b45282cad2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"41c6cc03d1fc4c35be4733db3749d465":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3bba3b7eaf24996a82de677cdc8b351":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f3e7745228e64f5894fb948559c29360":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da84abcf648e411480168c3b87ffb4ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"35dcbc99749b4c8ca85da311464a1f1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OQ4zTAe6s78f"},"source":["# 9章\n","- 以下で実行するコードには確率的な処理が含まれていることがあり、コードの出力結果と本書に記載されている出力例が異なることがあります。\n","- 本章で用いる「[日本語Wikipedia入力誤りデータセット](https://nlp.ist.i.kyoto-u.ac.jp/?%E6%97%A5%E6%9C%AC%E8%AA%9EWikipedia%E5%85%A5%E5%8A%9B%E8%AA%A4%E3%82%8A%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88)」は現在バージョン2が公開されていますが、本章では[バージョン1](https://nlp.ist.i.kyoto-u.ac.jp/?%E6%97%A5%E6%9C%AC%E8%AA%9EWikipedia%E5%85%A5%E5%8A%9B%E8%AA%A4%E3%82%8A%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88v1)を用いています。\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYAc8uDgGXNZ","executionInfo":{"status":"ok","timestamp":1631197510103,"user_tz":-540,"elapsed":410,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"3f25f214-20ce-4c38-d9f8-b643731022f3"},"source":["# 9-1\n","!mkdir chap9\n","%cd ./chap9"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/chap9\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13L45ApiGXNa","executionInfo":{"status":"ok","timestamp":1631197535375,"user_tz":-540,"elapsed":24456,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"b4a13ae4-d16c-479a-fad1-b246773fe160"},"source":["# 9-2\n","!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 pytorch-lightning==1.2.10"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.5.0\n","  Downloading transformers-4.5.0-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 4.0 MB/s \n","\u001b[?25hCollecting fugashi==1.1.0\n","  Downloading fugashi-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (486 kB)\n","\u001b[K     |████████████████████████████████| 486 kB 35.9 MB/s \n","\u001b[?25hCollecting ipadic==1.0.0\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[K     |████████████████████████████████| 13.4 MB 191 kB/s \n","\u001b[?25hCollecting pytorch-lightning==1.2.10\n","  Downloading pytorch_lightning-1.2.10-py3-none-any.whl (841 kB)\n","\u001b[K     |████████████████████████████████| 841 kB 32.3 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.62.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.6.4)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (1.9.0+cu102)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 42.2 MB/s \n","\u001b[?25hCollecting PyYAML!=5.4.*,>=5.1\n","  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 51.0 MB/s \n","\u001b[?25hCollecting fsspec[http]>=0.8.1\n","  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n","\u001b[K     |████████████████████████████████| 119 kB 46.7 MB/s \n","\u001b[?25hCollecting torchmetrics==0.2.0\n","  Downloading torchmetrics-0.2.0-py3-none-any.whl (176 kB)\n","\u001b[K     |████████████████████████████████| 176 kB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (2.6.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 40.0 MB/s \n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.12.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (57.4.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (3.17.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.4.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (3.3.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.39.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.37.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.34.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (4.2.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning==1.2.10) (3.7.4.3)\n","Collecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.10) (21.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 44.5 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 52.6 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.0.1)\n","Building wheels for collected packages: ipadic, future, PyYAML\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=c14f566e94f5f04467177087d70e303ffb8d7fa5ab95be14797eb776e5ebc02a\n","  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=601ff8949ce810f4cae3814fc805506d41a8266bacfc6e61c81e7ffec1001a0f\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44635 sha256=5b034e947a9b4b68156a19c42061de0435c6b9bf87e02eb4752937e7f4433df1\n","  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n","Successfully built ipadic future PyYAML\n","Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, tokenizers, sacremoses, PyYAML, future, transformers, pytorch-lightning, ipadic, fugashi\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed PyYAML-5.3.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.8.1 fugashi-1.1.0 future-0.18.2 ipadic-1.0.0 multidict-5.1.0 pytorch-lightning-1.2.10 sacremoses-0.0.45 tokenizers-0.10.3 torchmetrics-0.2.0 transformers-4.5.0 yarl-1.6.3\n"]}]},{"cell_type":"code","metadata":{"id":"0ULhAjFPGXNa","executionInfo":{"status":"ok","timestamp":1631197540271,"user_tz":-540,"elapsed":4913,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}}},"source":["# 9-3\n","import random\n","from tqdm import tqdm\n","import unicodedata\n","\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import BertJapaneseTokenizer, BertForMaskedLM\n","import pytorch_lightning as pl\n","\n","# 日本語の事前学習済みモデル\n","MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"MC1yL-SSGXNb","executionInfo":{"status":"ok","timestamp":1631197540272,"user_tz":-540,"elapsed":20,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}}},"source":["# 9-4\n","class SC_tokenizer(BertJapaneseTokenizer):\n","       \n","    def encode_plus_tagged(\n","        self, wrong_text, correct_text, max_length=128\n","    ):\n","        \"\"\"\n","        ファインチューニング時に使用。\n","        誤変換を含む文章と正しい文章を入力とし、\n","        符号化を行いBERTに入力できる形式にする。\n","        \"\"\"\n","        # 誤変換した文章をトークン化し、符号化\n","        encoding = self(\n","            wrong_text, \n","            max_length=max_length, \n","            padding='max_length', \n","            truncation=True\n","        )\n","        # 正しい文章をトークン化し、符号化\n","        encoding_correct = self(\n","            correct_text,\n","            max_length=max_length,\n","            padding='max_length',\n","            truncation=True\n","        ) \n","        # 正しい文章の符号をラベルとする\n","        encoding['labels'] = encoding_correct['input_ids'] \n","\n","        return encoding\n","\n","    def encode_plus_untagged(\n","        self, text, max_length=None, return_tensors=None\n","    ):\n","        \"\"\"\n","        文章を符号化し、それぞれのトークンの文章中の位置も特定しておく。\n","        \"\"\"\n","        # 文章のトークン化を行い、\n","        # それぞれのトークンと文章中の文字列を対応づける。\n","        tokens = [] # トークンを追加していく。\n","        tokens_original = [] # トークンに対応する文章中の文字列を追加していく。\n","        words = self.word_tokenizer.tokenize(text) # MeCabで単語に分割\n","        for word in words:\n","            # 単語をサブワードに分割\n","            tokens_word = self.subword_tokenizer.tokenize(word) \n","            tokens.extend(tokens_word)\n","            if tokens_word[0] == '[UNK]': # 未知語への対応\n","                tokens_original.append(word)\n","            else:\n","                tokens_original.extend([\n","                    token.replace('##','') for token in tokens_word\n","                ])\n","\n","        # 各トークンの文章中での位置を調べる。（空白の位置を考慮する）\n","        position = 0\n","        spans = [] # トークンの位置を追加していく。\n","        for token in tokens_original:\n","            l = len(token)\n","            while 1:\n","                if token != text[position:position+l]:\n","                    position += 1\n","                else:\n","                    spans.append([position, position+l])\n","                    position += l\n","                    break\n","\n","        # 符号化を行いBERTに入力できる形式にする。\n","        input_ids = self.convert_tokens_to_ids(tokens) \n","        encoding = self.prepare_for_model(\n","            input_ids, \n","            max_length=max_length, \n","            padding='max_length' if max_length else False, \n","            truncation=True if max_length else False\n","        )\n","        sequence_length = len(encoding['input_ids'])\n","        # 特殊トークン[CLS]に対するダミーのspanを追加。\n","        spans = [[-1, -1]] + spans[:sequence_length-2] \n","        # 特殊トークン[SEP]、[PAD]に対するダミーのspanを追加。\n","        spans = spans + [[-1, -1]] * ( sequence_length - len(spans) ) \n","\n","        # 必要に応じてtorch.Tensorにする。\n","        if return_tensors == 'pt':\n","            encoding = { k: torch.tensor([v]) for k, v in encoding.items() }\n","\n","        return encoding, spans\n","\n","    def convert_bert_output_to_text(self, text, labels, spans):\n","        \"\"\"\n","        推論時に使用。\n","        文章と、各トークンのラベルの予測値、文章中での位置を入力とする。\n","        そこから、BERTによって予測された文章に変換。\n","        \"\"\"\n","        assert len(spans) == len(labels)\n","\n","        # labels, spansから特殊トークンに対応する部分を取り除く\n","        labels = [label for label, span in zip(labels, spans) if span[0]!=-1]\n","        spans = [span for span in spans if span[0]!=-1]\n","\n","        # BERTが予測した文章を作成\n","        predicted_text = ''\n","        position = 0\n","        for label, span in zip(labels, spans):\n","            start, end = span\n","            if position != start: # 空白の処理\n","                predicted_text += text[position:start]\n","            predicted_token = self.convert_ids_to_tokens(label)\n","            predicted_token = predicted_token.replace('##', '')\n","            predicted_token = unicodedata.normalize(\n","                'NFKC', predicted_token\n","            ) \n","            predicted_text += predicted_token\n","            position = end\n","        \n","        return predicted_text"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["3716ce24971b46888a8e5c8a4039f569","e243c05139fa4d40b5686e2d44e94710","9779f522a866455d8752d682ad547fce","558085a6721c4307ba47d199bae5dcb1","12c701e661004815968c266a6d4c3f39","7d3953c604074d5c9d13c7e0e9305a1e","1b21db5a1f334860b2cf9cf15dfb6614","042072428cd3420392a0e3ce6ed48e63","233672f056824eb6a64dc733ba9264c3","3a50203ed76e4123beb66fc6ad728e1b","a310795d4e784b54b0721e85cc7146a7","08f894b1a91244808fb69ec50f7e2de1","cefb21e32dab42a1b75939a81eef323e","23d5d09797314b25a2fd78661e145897","a6f87ac9d26b4d4680f4c9fa305c9e9e","c934043aac174925b98c0ed88540e98a","a7bdf955d7d043f7be9434d6840bdde8","8f08ef83a0884ca3a2abb0fd3c0bbc29","1cd433d83c5942219f0659fbb05f44d9","c7b0b4f55ba54d1db73ae46f29ded42b","458c8ab270944cb8adee9ca249888981","8f5b39d1c75f472892fa33a9cb8b75d8"]},"id":"HBTlINuoGXNc","executionInfo":{"status":"ok","timestamp":1631197546480,"user_tz":-540,"elapsed":6227,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"df097604-1f4b-45a3-b91b-2dbdf13ed4a1"},"source":["# 9-5\n","tokenizer = SC_tokenizer.from_pretrained(MODEL_NAME)"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3716ce24971b46888a8e5c8a4039f569","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/258k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08f894b1a91244808fb69ec50f7e2de1","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/110 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e27NIdKYGXNc","executionInfo":{"status":"ok","timestamp":1631197546482,"user_tz":-540,"elapsed":13,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"09a7596e-b073-4690-b0d7-26ebd293c936"},"source":["# 9-6\n","wrong_text = '優勝トロフィーを変換した'\n","correct_text = '優勝トロフィーを返還した'\n","encoding = tokenizer.encode_plus_tagged(\n","    wrong_text, correct_text, max_length=12\n",")\n","print(encoding)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [2, 759, 18204, 11, 4618, 15, 10, 3, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], 'labels': [2, 759, 18204, 11, 8274, 15, 10, 3, 0, 0, 0, 0]}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLBWoRIcGXNd","executionInfo":{"status":"ok","timestamp":1631197546482,"user_tz":-540,"elapsed":7,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"31d7121c-ae88-4fa3-d710-0f1763d0a7dd"},"source":["# 9-7\n","wrong_text = '優勝トロフィーを変換した'\n","encoding, spans = tokenizer.encode_plus_untagged(\n","    wrong_text, return_tensors='pt'\n",")\n","print('# encoding')\n","print(encoding)\n","print('# spans')\n","print(spans)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["# encoding\n","{'input_ids': tensor([[    2,   759, 18204,    11,  4618,    15,    10,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n","# spans\n","[[-1, -1], [0, 2], [2, 7], [7, 8], [8, 10], [10, 11], [11, 12], [-1, -1]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7gH4oB9GXNd","executionInfo":{"status":"ok","timestamp":1631197546483,"user_tz":-540,"elapsed":6,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"bc00391b-15bd-43e4-f0ed-493762e29424"},"source":["# 9-8\n","predicted_labels = [2, 759, 18204, 11, 8274, 15, 10, 3]\n","predicted_text = tokenizer.convert_bert_output_to_text(\n","    wrong_text, predicted_labels, spans\n",")\n","print(predicted_text)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["優勝トロフィーを返還した\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":132,"referenced_widgets":["9992f74f0c2740748daf57db10e21b06","1419bc5ace0941e89dd5ccc46e3f6c7b","ada96e2d437c483a93a5564f3d14312b","6f994482f0ae47b98c82f88611232650","dc67e59186c44521b9710f2ac420693e","dcd2cc76094443a7933564f2e7945ec6","391cd293e8ef4bff91133e020e47e254","096f486c426f4f4bbadbc684742bafef","a0b0086061d44ce2a60f24fdf5306531","6d18306992b74f688c0eda66c78c287f","a2301e04a5a640289179a2cc90017a17","1fb19a3e278e4f6199dd2ac49cdd0cc0","565ae0aa43994a10a91deb516daa2602","73bd4e52f4d24a0c91e2bc097a0e1c89","03a296822f654bed96fbcc76fde7c7d3","cdd88c2ff77041bcaf4c6eb0b40a5514","27d36944757d4939ad4a03b45282cad2","41c6cc03d1fc4c35be4733db3749d465","a3bba3b7eaf24996a82de677cdc8b351","f3e7745228e64f5894fb948559c29360","da84abcf648e411480168c3b87ffb4ff","35dcbc99749b4c8ca85da311464a1f1e"]},"id":"zCFGE4xbGXNe","executionInfo":{"status":"ok","timestamp":1631197574727,"user_tz":-540,"elapsed":28249,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"0351ce7a-5d01-4657-e6bf-83684947a23a"},"source":["# 9-9\n","bert_mlm = BertForMaskedLM.from_pretrained(MODEL_NAME)\n","bert_mlm = bert_mlm.cuda()"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9992f74f0c2740748daf57db10e21b06","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/479 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fb19a3e278e4f6199dd2ac49cdd0cc0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"id":"J2DR-ls8GXNf","executionInfo":{"status":"ok","timestamp":1631197574730,"user_tz":-540,"elapsed":7,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}}},"source":["# 9-10\n","text = '優勝トロフィーを変換した。'\n","\n","# 符号化とともに各トークンの文章中の位置を計算しておく。\n","encoding, spans = tokenizer.encode_plus_untagged(\n","    text, return_tensors='pt'\n",")\n","encoding = { k: v.cuda() for k, v in encoding.items() }\n","\n","# BERTに入力し、トークン毎にスコアの最も高いトークンのIDを予測値とする。\n","with torch.no_grad():\n","    output = bert_mlm(**encoding)\n","    scores = output.logits\n","    labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist()\n","    \n","# ラベル列を文章に変換\n","predict_text = tokenizer.convert_bert_output_to_text(\n","    text, labels_predicted, spans\n",")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wc0mIVlnGXNf","executionInfo":{"status":"ok","timestamp":1631197574731,"user_tz":-540,"elapsed":7,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}}},"source":["# 9-11\n","data = [\n","    {\n","        'wrong_text': '優勝トロフィーを変換した。',\n","        'correct_text': '優勝トロフィーを返還した。',\n","    },\n","    {\n","        'wrong_text': '人と森は強制している。',\n","        'correct_text': '人と森は共生している。',\n","    }\n","]\n","\n","# 各データを符号化し、データローダへ入力できるようにする。\n","max_length=32\n","dataset_for_loader = []\n","for sample in data:\n","    wrong_text = sample['wrong_text']\n","    correct_text = sample['correct_text']\n","    encoding = tokenizer.encode_plus_tagged(\n","        wrong_text, correct_text, max_length=max_length\n","    )\n","    encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n","    dataset_for_loader.append(encoding)\n","\n","# データローダを作成\n","dataloader = DataLoader(dataset_for_loader, batch_size=2)\n","\n","# ミニバッチをBERTへ入力し、損失を計算。\n","for batch in dataloader:\n","    encoding = { k: v.cuda() for k, v in batch.items() }\n","    output = bert_mlm(**encoding)\n","    loss = output.loss # 損失"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0KBJLE4GXNg","executionInfo":{"status":"ok","timestamp":1631197582057,"user_tz":-540,"elapsed":7332,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"39bea0ec-c33a-4f96-cd42-0fd3550596c0"},"source":["# 9-12\n","!curl -L \"https://nlp.ist.i.kyoto-u.ac.jp/DLcounter/lime.cgi?down=https://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JWTD/jwtd.tar.gz&name=JWTD.tar.gz\" -o JWTD.tar.gz\n","!tar zxvf JWTD.tar.gz"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   243  100   243    0     0    347      0 --:--:-- --:--:-- --:--:--   347\n","100   268  100   268    0     0    327      0 --:--:-- --:--:-- --:--:--   327\n","100 64.9M  100 64.9M    0     0  14.6M      0  0:00:04  0:00:04 --:--:-- 18.9M\n","jwtd/\n","jwtd/train.jsonl\n","jwtd/test.jsonl\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-lflu5sGXNg","executionInfo":{"status":"ok","timestamp":1631197689904,"user_tz":-540,"elapsed":107849,"user":{"displayName":"大野有価","photoUrl":"","userId":"03079242618736976699"}},"outputId":"4fd382d9-027b-44fc-c038-4cad1121de5c"},"source":["# 9-13\n","def create_dataset(data_df):\n","\n","    tokenizer = SC_tokenizer.from_pretrained(MODEL_NAME)\n","\n","    def check_token_count(row):\n","        \"\"\"\n","        誤変換の文章と正しい文章でトークンに対応がつくかどうかを判定。\n","        （条件は上の文章を参照）\n","        \"\"\"\n","        wrong_text_tokens = tokenizer.tokenize(row['wrong_text'])\n","        correct_text_tokens = tokenizer.tokenize(row['correct_text'])\n","        if len(wrong_text_tokens) != len(correct_text_tokens):\n","            return False\n","        \n","        diff_count = 0\n","        threthold_count = 2\n","        for wrong_text_token, correct_text_token \\\n","            in zip(wrong_text_tokens, correct_text_tokens):\n","\n","            if wrong_text_token != correct_text_token:\n","                diff_count += 1\n","                if diff_count > threthold_count:\n","                    return False\n","        return True\n","\n","    def normalize(text):\n","        \"\"\"\n","        文字列の正規化\n","        \"\"\"\n","        text = text.strip()\n","        text = unicodedata.normalize('NFKC', text)\n","        return text\n","\n","    # 漢字の誤変換のデータのみを抜き出す。\n","    category_type = 'kanji-conversion'\n","    data_df.query('category == @category_type', inplace=True) \n","    data_df.rename(\n","        columns={'pre_text': 'wrong_text', 'post_text': 'correct_text'}, \n","        inplace=True\n","    )\n","    \n","    # 誤変換と正しい文章をそれぞれ正規化し、\n","    # それらの間でトークン列に対応がつくもののみを抜き出す。\n","    data_df['wrong_text'] = data_df['wrong_text'].map(normalize) \n","    data_df['correct_text'] = data_df['correct_text'].map(normalize)\n","    kanji_conversion_num = len(data_df)\n","    data_df = data_df[data_df.apply(check_token_count, axis=1)]\n","    same_tokens_count_num = len(data_df)\n","    print(\n","        f'- 漢字誤変換の総数：{kanji_conversion_num}',\n","        f'- トークンの対応関係のつく文章の総数: {same_tokens_count_num}',\n","        f'  (全体の{same_tokens_count_num/kanji_conversion_num*100:.0f}%)',\n","        sep = '\\n'\n","    )\n","    return data_df[['wrong_text', 'correct_text']].to_dict(orient='records')\n","\n","# データのロード\n","train_df = pd.read_json(\n","    './jwtd/train.jsonl', orient='records', lines=True\n",")\n","test_df = pd.read_json(\n","    './jwtd/test.jsonl', orient='records', lines=True\n",")\n","\n","# 学習用と検証用データ\n","print('学習と検証用のデータセット：')\n","dataset = create_dataset(train_df)\n","random.shuffle(dataset)\n","n = len(dataset)\n","n_train = int(n*0.8)\n","dataset_train = dataset[:n_train]\n","dataset_val = dataset[n_train:]\n","\n","# テストデータ\n","print('テスト用のデータセット：')\n","dataset_test = create_dataset(test_df)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["学習と検証用のデータセット：\n","- 漢字誤変換の総数：235490\n","- トークンの対応関係のつく文章の総数: 171708\n","  (全体の73%)\n","テスト用のデータセット：\n","- 漢字誤変換の総数：3061\n","- トークンの対応関係のつく文章の総数: 2252\n","  (全体の74%)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlr9SXDNGXNh","outputId":"46135aff-2145-4691-cdc0-c0cef3332e79"},"source":["# 9-14\n","def create_dataset_for_loader(tokenizer, dataset, max_length):\n","    \"\"\"\n","    データセットをデータローダに入力可能な形式にする。\n","    \"\"\"\n","    dataset_for_loader = []\n","    for sample in tqdm(dataset):\n","        wrong_text = sample['wrong_text']\n","        correct_text = sample['correct_text']\n","        encoding = tokenizer.encode_plus_tagged(\n","            wrong_text, correct_text, max_length=max_length\n","        )\n","        encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n","        dataset_for_loader.append(encoding)\n","    return dataset_for_loader\n","\n","tokenizer = SC_tokenizer.from_pretrained(MODEL_NAME)\n","\n","# データセットの作成\n","max_length = 32\n","dataset_train_for_loader = create_dataset_for_loader(\n","    tokenizer, dataset_train, max_length\n",")\n","dataset_val_for_loader = create_dataset_for_loader(\n","    tokenizer, dataset_val, max_length\n",")\n","\n","# データローダの作成\n","dataloader_train = DataLoader(\n","    dataset_train_for_loader, batch_size=32, shuffle=True\n",")\n","dataloader_val = DataLoader(dataset_val_for_loader, batch_size=256)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 137366/137366 [01:42<00:00, 1334.65it/s]\n"," 77%|███████▋  | 26507/34342 [00:19<00:05, 1361.67it/s]"]}]},{"cell_type":"code","metadata":{"id":"c-j7R6z0GXNh"},"source":["# 9-15\n","class BertForMaskedLM_pl(pl.LightningModule):\n","        \n","    def __init__(self, model_name, lr):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.bert_mlm = BertForMaskedLM.from_pretrained(model_name)\n","        \n","    def training_step(self, batch, batch_idx):\n","        output = self.bert_mlm(**batch)\n","        loss = output.loss\n","        self.log('train_loss', loss)\n","        return loss\n","        \n","    def validation_step(self, batch, batch_idx):\n","        output = self.bert_mlm(**batch)\n","        val_loss = output.loss\n","        self.log('val_loss', val_loss)\n","   \n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n","\n","checkpoint = pl.callbacks.ModelCheckpoint(\n","    monitor='val_loss',\n","    mode='min',\n","    save_top_k=1,\n","    save_weights_only=True,\n","    dirpath='model/'\n",")\n","\n","trainer = pl.Trainer(\n","    gpus=1,\n","    # max_epochs=5,\n","    max_epochs=1,\n","    callbacks=[checkpoint]\n",")\n","\n","# ファインチューニング\n","model = BertForMaskedLM_pl(MODEL_NAME, lr=1e-5)\n","trainer.fit(model, dataloader_train, dataloader_val)\n","best_model_path = checkpoint.best_model_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2eNTz6OsvVP"},"source":["# 9-16\n","def predict(text, tokenizer, bert_mlm):\n","    \"\"\"\n","    文章を入力として受け、BERTが予測した文章を出力\n","    \"\"\"\n","    # 符号化\n","    encoding, spans = tokenizer.encode_plus_untagged(\n","        text, return_tensors='pt'\n","    ) \n","    encoding = { k: v.cuda() for k, v in encoding.items() }\n","\n","    # ラベルの予測値の計算\n","    with torch.no_grad():\n","        output = bert_mlm(**encoding)\n","        scores = output.logits\n","        labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist()\n","\n","    # ラベル列を文章に変換\n","    predict_text = tokenizer.convert_bert_output_to_text(\n","        text, labels_predicted, spans\n","    )\n","\n","    return predict_text\n","\n","# いくつかの例に対してBERTによる文章校正を行ってみる。\n","text_list = [\n","    'ユーザーの試行に合わせた楽曲を配信する。',\n","    'メールに明日の会議の史料を添付した。',\n","    '乳酸菌で牛乳を発行するとヨーグルトができる。',\n","    '突然、子供が帰省を発した。'\n","]\n","\n","# トークナイザ、ファインチューニング済みのモデルのロード\n","tokenizer = SC_tokenizer.from_pretrained(MODEL_NAME)\n","model = BertForMaskedLM_pl.load_from_checkpoint(best_model_path)\n","bert_mlm = model.bert_mlm.cuda()\n","\n","for text in text_list:\n","    predict_text = predict(text, tokenizer, bert_mlm) # BERTによる予測\n","    print('---')\n","    print(f'入力：{text}')\n","    print(f'出力：{predict_text}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zwqdG4SGXNi"},"source":["# 9-17\n","# BERTで予測を行い、正解数を数える。\n","correct_num = 0 \n","for sample in tqdm(dataset_test):\n","    wrong_text = sample['wrong_text']\n","    correct_text = sample['correct_text']\n","    predict_text = predict(wrong_text, tokenizer, bert_mlm) # BERT予測\n","   \n","    if correct_text == predict_text: # 正解の場合\n","        correct_num += 1\n","\n","print(f'Accuracy: {correct_num/len(dataset_test):.2f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUj8v6dPGXNj"},"source":["# 9-18\n","correct_position_num = 0 # 正しく誤変換の漢字を特定できたデータの数\n","for sample in tqdm(dataset_test):\n","    wrong_text = sample['wrong_text']\n","    correct_text = sample['correct_text']\n","    \n","    # 符号化\n","    encoding = tokenizer(wrong_text)\n","    wrong_input_ids = encoding['input_ids'] # 誤変換の文の符合列\n","    encoding = {k: torch.tensor([v]).cuda() for k,v in encoding.items()}\n","    correct_encoding = tokenizer(correct_text)\n","    correct_input_ids = correct_encoding['input_ids'] # 正しい文の符合列\n","    \n","    # 文章を予測\n","    with torch.no_grad():\n","        output = bert_mlm(**encoding)\n","        scores = output.logits\n","        # 予測された文章のトークンのID\n","        predict_input_ids = scores[0].argmax(-1).cpu().numpy().tolist() \n","\n","    # 特殊トークンを取り除く\n","    wrong_input_ids = wrong_input_ids[1:-1]\n","    correct_input_ids =  correct_input_ids[1:-1]\n","    predict_input_ids =  predict_input_ids[1:-1]\n","    \n","    # 誤変換した漢字を特定できているかを判定\n","    # 符合列を比較する。\n","    detect_flag = True\n","    for wrong_token, correct_token, predict_token \\\n","        in zip(wrong_input_ids, correct_input_ids, predict_input_ids):\n","\n","        if wrong_token == correct_token: # 正しいトークン\n","            # 正しいトークンなのに誤って別のトークンに変換している場合\n","            if wrong_token != predict_token: \n","                detect_flag = False\n","                break\n","        else: # 誤変換のトークン\n","            # 誤変換のトークンなのに、そのままにしている場合\n","            if wrong_token == predict_token: \n","                detect_flag = False\n","                break\n","\n","    if detect_flag: # 誤変換の漢字の位置を正しく特定できた場合\n","        correct_position_num += 1\n","        \n","print(f'Accuracy: {correct_position_num/len(dataset_test):.2f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNQZDhDBygoS"},"source":[""],"execution_count":null,"outputs":[]}]}