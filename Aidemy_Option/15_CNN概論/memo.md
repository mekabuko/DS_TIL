# メモ
## CNN基礎
### 1.1 基礎理論
#### 1.1.1 初めに
#### 1.1.2 CNN概要
- 畳み込みニューラルネットワーク(Convolutional Neural Networks, CNNs)は、主に画像データの処理に使われるニューラルネットワーク
- 畳み込み層とプーリング層という2種類の層を含む順伝幡型ネットワーク
    - 畳み込み層: 画像からのエッジ抽出等の特徴抽出を行う
    - プーリング層: 畳み込み層で抽出された特徴を平行移動などでも影響を受けないようにロバスト性を与える
### 1.2 畳み込み層
#### 1.2.1 畳み込みの定義
- あるサイズのフィルターをかけて、フィルタの持つパターンとよく似たものがどこにあるかを探す
#### 1.2.2 パディング
- 畳み込み処理で画像が小さくなってしまわないように、入力画像に「ふち」をつけてサイズを調整すること
    - ０で埋める手法をゼロパディングと呼ぶ
- パディングによって、画像の端にある物体を検出しやすくなる効果も期待できる
#### 1.2.3 ストライド stride
- フィルタを何ピクセルずつずらして、適用していくか
- 大きくすると速くなるが、取りこぼす可能性が高くなるので、可能であれば２以上にすることを避けたい
    - ただし、プーリング層では２以上にするのが普通
### 1.3 プーリング層
#### 1.3.1 プーリングとは
- ある場所でのネットワークの出力を、周辺の出力の要約統計（平均や最大など）で置き換える処理
- 入力の小さな動きの影響を少なくするので、ロバスト性を高める効果が期待できる
#### 1.3.2 プーリングの性質
- 堅牢性が高まることで、特に「どこにあるか」よりも「あるかどうか」を探すような場合には、特に効果が高い
- データサイズの圧縮にもつながり、計算効率やメモリ効率が上がる
## CNN実例
### 2.1 応用理論
#### 2.1.1 構造出力
- 出力は、分類のクラスや、回帰の実数値だけではなく、高次元な構造オブジェクト（テンソル）も可能
#### 2.1.2 データの種類
- データは、通常複数のチャネルから構成される
    - 各チャネルは、空間や時間におけるある点の観測値
- CNN の利点の一つは、空間的な大きさの異なる入力も処理できること
    - 行列掛け算に基づくNNでは不可能だった
#### 2.1.3 効率的な畳み込みアルゴリズム
- 可分：d次元のカーネルが d個のベクトルの外積で表現できる場合
- 可分なら、素朴なCNNよりも、それぞれのカーネルに分解して、掛け合わせた方が効率的
- このように、効率化/高速化する手法の研究も活発
#### 2.1.4 ランダムあるいは教師なし特徴量
- CNNの訓練で一番計算コストがかかるのは、勾配効果法による特徴量の学習
    - 出力層の計算は、プーリングをへて特徴量が削減されているので、そこまで大きな計算コストは不要。
- そのため、教師あり学習を利用せずに、畳み込みカーネルを求められると、高速化が期待できる
    1. ランダムに初期化する方法
    2. 人手で背形する方法
    3. 教師なしの基準で特徴量を学習する方法
- しかし現在では、計算リソースの発達もあり、ほとんどCNNの訓練のたびにネットワーク全体で順伝播と逆伝播を利用する通常の方法を用いている
### 2.2 画像認識の有名なモデル
- ILSVRC(画像認識のコンペ)の最近の優勝モデルを紹介
#### 2.2.1 ImageNet
- 100万枚を超える画像のデータセット
- 画像とそのクラスラベルの紐付けられている
- ImageNetで学習したモデルの再学習を用いた、転移学習も有用な方法
#### 2.2.2 「AlexNet」(2012年, 8層)
- Deep Learning の魁
- 全ての層で使われている活性化関数はReLU関数
- Pooling層では、Overlapping PoolingのMax Poolingを使用
#### 2.2.3 「VGGNet」(2014年,19層)
- 畳み込み層とプーリング層からなる、基本的なCNN
- 重みのある層を全部で19層にまで重ねてdeepにしている点が特徴
#### 2.2.4 「GoogLeNet」(2014年, 22層)
- 基本的にはCNNと同じ構造
- ネットワークが縦方向の深さだけでなく、横方向にも深さ(広がり)を持っているという点が特徴
- 小さなネットワークを１つのモジュールと定義(Inception module)して、モジュールの積み重ねでネットワークを構成
    - Inception module: サイズの異なるフィルターとプーリングを複数適用し、その結果を結合
- サイズが1×1のフィルターの畳み込み層を多くの場所で使用。チャンネル方向にサイズを減らすことで、パラメータの次元削減や処理の高速化に貢献。
- Global Average Pooling (GAP): 入力された特徴マップのサイズと同じサイズのAverage Poolingを行うPooling層
    - CNNの最後の畳み込み層の出力チャネル数を最終的な出力の次元数（クラス数）と同一とし、その後GAP（およびsoftmax）を適用することで、全結合層を利用することなく最終的な出力を得る
    - 全結合層を利用しないことでパラメータ数を大きく削減し、過学習を防ぐ
- 学習では、ネットワークの途中から分岐させたサブネットワークにおいてもクラス分類を行い、Auxiliary Loss(ロス)を追加する
    - ネットワークの中間層に直接誤差を伝搬させることで、勾配消失を防ぐとともにネットワークの正則化(つまり学習の効率化)を実現
#### 2.2.5 「ResNet」 (Residual Network ,2015年, 152層)
- 一般的な人間の認識能力を超えたとさえ言われる誤認識率3.57%を達成
- ResNetの登場以前は勾配消失問題から、層をあまりに深くすることは難しかった
    - 層をまたがる結合としてIdentity mapping を使用。
    - 入力を、層をスキップしながら結合することで、スキップコネクションの内側の層はブロックの入出力の残差を学習する
    - ブロックへの入力にこれ以上の変換が必要ない場合は重みが0となり、小さな変換が求められる場合は対応する小さな変動をより見つけやすくなることが期待できる
- 上記によって、深い構造を可能にした
### 2.3 物体検出
#### 2.3.1 物体検出
- 画像中から「物体の位置」の特定を含めてクラス分類を行う問題
- IoU(Intersection Over Union): 物体検出の精度評価指標
    - IOU = (予測領域と正解領域の重なる部分)/(予測領域と正解領域の合計)
- Non-Maximum Suppression: 1つの物体に対して複数回検出されたものを1つの領域に統合するための処理
    - 物体ごとに検出された領域の中で一番スコアが高いものだけが出力される
#### 2.3.2 「R-CNN」(2014)
- 以下のアルゴリズム
    1. オブジェクトらしい領域(何かしらがありそうな領域)をSelective Searchという手法を用いて探し出し、画像から、物体候補を探し出す
    2. 物体候補の領域を全て一定の大きさにリサイズしてCNNにかけ、特徴マップを出力
    3. 特徴マップを使って、複数のSVMによりカテゴリ識別を行い、回帰によって正確な領域を測定
- R-CNNでは特徴抽出のCNN,カテゴリ推定のSVMなど各学習の目的ごとに別々に学習させる必要がある
- 実行時間が遅い(GPUを使って10~45s/image)
#### 2.3.3 「SPPnet」(2014)
- アイディアとしては、画像をリサイズするのではなく、特徴マップをプーリングするときにリサイズ処理を行う
- R-CNNでは、固定サイズの画像を入力として識別していたが、 SPPnetでは、Spatial Pyramid Pooling (SPP)という手法を用いることで、 CNNで畳み込んだ最終層の特徴マップを縦横可変サイズで取り扱えるようにした
    - これにより、R-CNNのように大量の物体量領域ごとにCNNで特徴抽出するのでなく(R-CNNの物体候補はかなり領域の重複が多いため、重複する画像領域をCNNで特徴抽出するのは無駄が生じる)、 画像１枚から大きな特徴マップを作成した後、物体候補の領域の特徴をSPPによってベクトル化することで、スピードはGPU上にて24-102倍に高速化
- 各学習の目的ごとに別々に学習させる必要がある欠点は克服できず
#### 2.3.4 「Fast R-CNN」(2015)
- R-CNNやSPPnetの「学習の目的ごとに別々に学習させる必要がある」という欠点を解決した
- アルゴリズムとしては
    1. RoI pooling layerという、SPPのpyramid構造を取り除いたシンプルな幅可変プーリングを行う
    2. カテゴリ分類と、回帰による領域の決定を同時に学習させるためのmulti-task lossによって1回で学習させる
    3. オンラインで教師データを生成する工夫の提案
- またmulti-task lossの導入により、Back-Propagationが全層に適用できるようになったため、全ての層の学習が可能に
- Faster R-CNN: 物体候補領域の識別も、CNNで行う手法（Fast R-CNN は Selective Searchを使用）
#### 2.3.5 「YOLO(You Only Look Once)」(2016)
- 予め画像全体をグリッド分割しておき各領域ごとに物体のクラスと領域を求める、という方法を提案
- CNNのアーキテクチャがシンプルになったため、Faster R-CNNに識別精度は少し劣るが、検出速度では向上
- スライド窓や物体候補を使った手法と違い、1枚の画像の全ての範囲を学習時に利用するため、周辺の背景も同時に学習することが可能
    - これにより、背景の誤検出を抑えることができるようになり、背景の誤検出はFast R-CNNの約半分に抑えることが可能になった
- 欠点として、分割されたグリッドサイズは固定かつ、グリッド内で識別できるクラスは1つ、 検出できる物体の数は2つ
    - グリッド内に大量のオブジェクトが映ってしまうような場合は精度が出ない
#### 2.3.6 「SSD(Single Shot MultiBox Detecter)」(2016)
- YOLOより高速で、Faster R-CNNと同等の精度を実現するアルゴリズム
### 2.4 セマンティックセグメンテーション
#### 2.4.1 セマンティックセグメンテーション
- 画像に対してピクセルレベルでクラス分類を行う問題
- 学習：ピクセル単位でオブジェクトごとに色付けされた教師データを使って学習を行う
- 推論：入力画像の全てのピクセルに対して、クラス分類を行う
#### 2.4.2 FCN(Fully Convolutional Network)
- 全てが畳み込み層から構成されるネットワーク
- 一般的なCNNが全結合層を含むのに対して、FCNでは全結合層を「同じ働きをする畳み込み層」に置き換える
#### 2.4.3 「SegNet」(2015)
- セグメンテーションの解像度を上げるために、Max Poolingインデックスがデコーダへ転移される。