# サマリ

# メモ
## モデル圧縮の概要
### 1.1 モデル圧縮の概要
#### 1.1.1 モデル圧縮とは何か？
- ディープラーニングは、一般には層を増やせば精度が上がるが、その分計算量やメモリ使用量も増える
- モデル圧縮：大規模なモデルのパラメータを加工することで、精度を保ちながらモデルの軽量化を行い、処理速度を上げること
#### 1.1.2 モデル圧縮を行う理由
- エッジAIの普及: 工場の現場など、エッジのデバイスで予測や分類をするエッジAIが普及してきた
    - エッジデバイスは、一般的にそこまで高性能ではない
    - 特にエッジでよく用いられる画像分類や物体検出は、層が多いディープラーニングが多い
- その中で、モデルの圧縮が求められるようになってきている
#### 1.1.3 モデル圧縮の手法
この後で詳細を学ぶ「蒸留」「プルーニング」「量子化」が主要な手法
## 蒸留
### 2.1 蒸留
#### 2.1.1 概要
- 別のニューラルネットワークが学習した情報を使ってモデルの学習をするテクニック
    - 情報の供給元となるネットワークを「教師ネットワーク」や「教師モデル」呼ぶ
    - 教師から情報を受けて学習するネットワークを「生徒ネットワーク」や「生徒モデル」、「蒸留モデル」と呼ぶ
- 蒸留によって、計算量を抑えた精度を高いモデル作成が期待できる → モデル圧縮の方法としても適用可能
- ただし、教師モデルと生徒モデル、全体での学習にかかる計算量は、生徒モデルだけを作るときよりも大きくなる
#### 2.1.2 メリット
- 計算量の少ないモデルが作れる
- 学習データ不足を補う
- 多数の分類をするモデルが作れる
- 「敵対的摂動」に強いモデルが作れる
    - 敵対的摂動: モデルの出力を意図的に操作するために、入力データに微細な変化を加えるといった、いわゆる「摂動」と呼ばれる操作を使う手法
## プルーニング
### 3.1 プルーニング
#### 3.1.1 概要
- 学習済みのニューラルネットワークのユニット間の接続を削除して、モデルのパラメータ数や計算量を削減
    1. ニューラルネットワークを学習する
    2. 重みの絶対値が小さい入力を無くす（ユニット間の接続を切る）
    3. ニューラルネットワークをもう一度訓練し、2.に戻る
    4. ネットワークが設定したサイズになったら終了する
- スパースディープラーニング（スパース化）：予めプルーニングしやすいように学習する手法
#### 3.1.2 メリット
- 予測精度に影響が少ないユニット間の接続を削除し、再学習
- 予測精度を大きく下げることなく、軽量化し、計算量を削減することが可能
## 量子化
### 4.1 量子化
#### 4.1.1 概要
- 学習済みニューラルネットワークの演算を浮動小数点数演算から整数演算に変換すること
#### 4.1.2 メリット
- bit数が小さくなることでメモリー消費が減り、整数型への変換によって計算量が削減される
- モデルの予測精度はやや劣化
